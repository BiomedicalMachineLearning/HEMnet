{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import io\n",
    "from ipywidgets import interact\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import openslide\n",
    "from openslide import open_slide\n",
    "import pandas as pd\n",
    "from PIL import Image, ImageOps\n",
    "import seaborn as sns\n",
    "import SimpleITK as sitk\n",
    "from skimage.color import rgb2hed\n",
    "from skimage.exposure import histogram\n",
    "from skimage.filters import threshold_otsu\n",
    "from skimage import morphology\n",
    "import time\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SLIDES_PATH = '/90days/s4596423/Data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/gpfs1/scratch/90days/s4596423/Data'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(SLIDES_PATH)\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1820_N_10545A_2_HandE.svs',\n",
       " '1820_N_10545A_4_TP53.svs',\n",
       " '2148_N_11397A_2_HandE.svs',\n",
       " '2148_N_11397A_4_TP53.svs',\n",
       " '2148_T_11393A_2_HandE.svs',\n",
       " '2148_T_11393A_4_TP53.svs',\n",
       " '2171_N_11521A_2_HandE.svs',\n",
       " '2171_N_11521A_4_TP53.svs',\n",
       " '2171_T_11524A_2_HandE.svs',\n",
       " '2171_T_11524A_4_TP53.svs']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slides = []\n",
    "for infile in glob.glob('*.svs'):\n",
    "    file, ext = os.path.splitext(infile)\n",
    "    slides.append(infile)\n",
    "slides.sort()\n",
    "slides\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp53_slide = open_slide('2171_T_11524A_4_TP53.svs')\n",
    "he_slide = open_slide('2171_T_11524A_2_HandE.svs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def highest_mag(slide):\n",
    "    \"\"\"Returns the highest magnification for the slide\n",
    "    \"\"\"\n",
    "    return int(slide.properties['aperio.AppMag'])\n",
    "\n",
    "def level_mags(slide):\n",
    "    \"\"\"Returns the magnification for each level in a slide\n",
    "    \"\"\"\n",
    "    return [highest_mag(slide)/downsample for downsample in slide.level_downsamples]\n",
    "\n",
    "def get_level_size(slide, level):\n",
    "    \"\"\"Returns the dimensions of a level\n",
    "    \"\"\"\n",
    "    return slide.level_dimensions[level]\n",
    "\n",
    "def get_level_mag(slide, level):\n",
    "    \"\"\"Returns the magnification at a particular level\n",
    "    \"\"\"\n",
    "    return level_mags(slide)[level]\n",
    "\n",
    "def get_level_for_mag(slide, mag):\n",
    "    \"\"\"Get the level corresponding to a certain magnification, if available\n",
    "    \"\"\"\n",
    "    level_mags_rounded = list(np.round(level_mags(slide), decimals = 2))\n",
    "    if mag in level_mags_rounded:\n",
    "        return level_mags_rounded.index(mag)\n",
    "    else: \n",
    "        return None\n",
    "    \n",
    "def get_mag_for_size(slide, size):\n",
    "    max_size = slide.dimensions\n",
    "    max_mag = highest_mag(slide)\n",
    "    downsample = np.average([max_dim/size_dim for max_dim, size_dim in zip(max_size, size)])\n",
    "    return max_mag/downsample\n",
    "\n",
    "def get_size_for_mag(slide, mag):\n",
    "    max_size = slide.dimensions\n",
    "    max_mag = highest_mag(slide)\n",
    "    downsample = max_mag/mag\n",
    "    return [np.int(np.round(dim/downsample)) for dim in max_size]\n",
    "\n",
    "def read_slide_at_mag(slide, mag):\n",
    "    exact_level = get_level_for_mag(slide, mag)\n",
    "    if exact_level is not None:\n",
    "        return slide.read_region((0,0), exact_level, get_level_size(slide, exact_level))\n",
    "    else:\n",
    "        max_size = slide.dimensions\n",
    "        region_size = tuple(get_size_for_mag(slide, mag))\n",
    "        downsample = np.average([max_dim/region_dim for max_dim, region_dim in zip(max_size, region_size)])\n",
    "        best_level = slide.get_best_level_for_downsample(downsample)\n",
    "        best_level_size = get_level_size(slide, best_level)\n",
    "        best_level_img = slide.read_region((0,0), best_level, best_level_size)\n",
    "        return best_level_img.resize(region_size, resample = Image.BICUBIC)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################\n",
    "# Image Filtering Functions #\n",
    "#############################\n",
    "\n",
    "def filter_green_channel(img, g_thresh = 240):\n",
    "    new_img = img.copy()\n",
    "    pixels = new_img.load()\n",
    "    for i in range(img.size[0]):   #For every column\n",
    "        for j in range(img.size[1]):    #For every row\n",
    "            if pixels[i,j][2] > g_thresh:\n",
    "                pixels[i,j] = (255,255,255)\n",
    "    return new_img        \n",
    "\n",
    "def filter_green_fast(img, g_thresh = 240):\n",
    "    #About 18x faster than previous implementation\n",
    "    img = img.convert('RGB')\n",
    "    r, g, b = img.split()\n",
    "    green_mask = (np.array(g) > 240)*255\n",
    "    green_mask_img = Image.fromarray(green_mask.astype(np.uint8), 'L')\n",
    "    white_image = Image.new('RGB', img.size, (255,255,255))\n",
    "    img_filtered = img.copy()\n",
    "    img_filtered.paste(white_image, mask = green_mask_img)\n",
    "    return img_filtered\n",
    "\n",
    "def filter_grays(img, tolerance = 3):\n",
    "    new_img = img.convert('RGB')\n",
    "    pixels = new_img.load()\n",
    "    for i in range(img.size[0]):\n",
    "        for j in range(img.size[1]):\n",
    "            r, g, b = pixels[i,j]\n",
    "            rg_diff, rb_diff, gb_diff = abs(r-g) <= tolerance, abs(r-b) <= tolerance, abs(g-b) <= tolerance\n",
    "            if rg_diff and rb_diff and gb_diff:\n",
    "                pixels[i,j] = (255,255,255)\n",
    "    return new_img\n",
    "\n",
    "def filter_otsu_global(img, mode = 'PIL'):\n",
    "    img_gray = img.convert('L')\n",
    "    threshold = threshold_otsu(np.array(img_gray))\n",
    "    img_binary = np.array(img_gray) > threshold\n",
    "    if mode == '1':\n",
    "        return img_binary\n",
    "    else:\n",
    "        return binary_array_to_pil(img_binary)\n",
    "\n",
    "def binary_array_to_pil(array):\n",
    "    img_shape = array.shape\n",
    "    img = Image.new('1', img_shape)\n",
    "    int_list = array.astype(int).tolist()\n",
    "    pixels = img.load()\n",
    "    for i in range(img.size[0]):\n",
    "        for j in range(img.size[1]):\n",
    "            pixels[i,j] = int_list[i][j]\n",
    "    return ImageOps.mirror(img).rotate(90, expand = True) #Not sure why this is necessary\n",
    "\n",
    "def white_pixels_to_black(img):\n",
    "    new_img = img.convert('RGB')\n",
    "    pixels = new_img.load()\n",
    "    for i in range(img.size[0]):\n",
    "        for j in range(img.size[1]):\n",
    "            rgb = pixels[i,j]\n",
    "            if rgb == (255,255,255):\n",
    "                pixels[i,j] = (0,0,0)\n",
    "    return new_img\n",
    "\n",
    "def tile_gen(img, tile_size):\n",
    "    '''Generates tiles for Pillow images\n",
    "    '''\n",
    "    width, height = img.size\n",
    "    x_tiles = int(np.floor(width/tile_size))\n",
    "    y_tiles = int(np.floor(height/tile_size))\n",
    "    yield (x_tiles, y_tiles)\n",
    "    for y in range(y_tiles):\n",
    "        for x in range(x_tiles):\n",
    "            x_coord = x*tile_size\n",
    "            y_coord = y*tile_size\n",
    "            yield img.crop((x_coord, y_coord, np.int(np.round(x_coord+tile_size)), np.int(np.round(y_coord+tile_size))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuple(get_size_for_mag(tp53_slide, 10))\n",
    "SLIDE_MAG = 5\n",
    "he = read_slide_at_mag(he_slide, SLIDE_MAG)\n",
    "tp53 = read_slide_at_mag(tp53_slide, SLIDE_MAG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_itk_from_pil(pil_img):\n",
    "    return sitk.GetImageFromArray(np.array(pil_img))\n",
    "\n",
    "def get_pil_from_itk(itk_img):\n",
    "    return Image.fromarray(sitk.GetArrayFromImage(itk_img).astype(np.uint8))\n",
    "\n",
    "def show_alignment_gray(fixed_img, moving_img, resize = None):\n",
    "    blank_img = Image.new(('L'), fixed_img.size, color = 0)\n",
    "    comparison = Image.merge('RGB', [moving_img, fixed_img, blank_img])\n",
    "    if resize is None:\n",
    "        return comparison\n",
    "    else: \n",
    "        downsample = max(comparison.size)/resize\n",
    "        final_size = tuple([np.int(np.round(dim/downsample)) for dim in comparison.size])\n",
    "        return comparison.resize(final_size, resample = Image.BICUBIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elastix_params_for_mag(mag):\n",
    "    a_param_map = sitk.GetDefaultParameterMap('affine')\n",
    "    a_param_map['MaximumNumberOfIterations'] = [str(mag*512)]\n",
    "    #a_param_map['NumberOfSpatialSamples'] = [str(mag**2*2048)]\n",
    "    a_param_map['NumberOfSpatialSamples'] = ['2048']\n",
    "    print('Number of Affine Spatial Samples: ', a_param_map['NumberOfSpatialSamples'])\n",
    "    b_param_map = sitk.GetDefaultParameterMap('bspline')\n",
    "    b_param_map['NumberOfResolutions'] = ['5']\n",
    "    b_param_map['GridSpacingSchedule'] = ['6.6','4.0','2.6', '1.6', '1.0']\n",
    "    b_param_map['Transform'] = ['RecursiveBSplineTransform']\n",
    "    b_param_map['MaximumNumberOfIterations'] = [str(mag*1024)]\n",
    "    print('Max BSpline Iterations: ', b_param_map['MaximumNumberOfIterations'])\n",
    "    #b_param_map['NumberOfSpatialSamples'] = [str(mag**2*4096)]\n",
    "    b_param_map['NumberOfSpatialSamples'] = ['4096']\n",
    "    print('Number of BSpline Spatial Samples: ', b_param_map['NumberOfSpatialSamples'])\n",
    "    #b_param_map['FinalGridSpacingInPhysicalUnits'] = [str((mag)*20)]\n",
    "    b_param_map['FinalGridSpacingInPhysicalUnits'] = ['1080','540', '180', '60', '20']\n",
    "    print('Final Grid Spacing in Physical Units: ', b_param_map['FinalGridSpacingInPhysicalUnits'])\n",
    "    b_param_map['Metric'] = ['NormalizedMutualInformation']   #Faster with unnormalised version\n",
    "    param_map_vector = sitk.VectorOfParameterMap()\n",
    "    param_map_vector.append(a_param_map)\n",
    "    param_map_vector.append(b_param_map)\n",
    "    return param_map_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Affine Spatial Samples:  ('2048',)\n",
      "Max BSpline Iterations:  ('5120',)\n",
      "Number of BSpline Spatial Samples:  ('4096',)\n",
      "Final Grid Spacing in Physical Units:  ('1080', '540', '180', '60', '20')\n"
     ]
    }
   ],
   "source": [
    "tp53_gray = tp53.convert('L')\n",
    "he_gray = he.convert('L')\n",
    "#---------------\n",
    "tp53_itk = get_itk_from_pil(tp53_gray)\n",
    "he_itk = get_itk_from_pil(he_gray)\n",
    "#---------------\n",
    "fixed_img = he_itk\n",
    "moving_img = tp53_itk\n",
    "param_map = elastix_params_for_mag(SLIDE_MAG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "elastix = sitk.ElastixImageFilter()\n",
    "elastix.SetFixedImage(fixed_img)\n",
    "elastix.SetMovingImage(moving_img)\n",
    "elastix.LogToFileOn()\n",
    "\n",
    "elastix.SetParameterMap(param_map)\n",
    "#elastix.LogToConsoleOn()\n",
    "elastix.Execute()\n",
    "\n",
    "result_img = elastix.GetResultImage()\n",
    "transform_param_map = elastix.GetTransformParameterMap()\n",
    "\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tp53_aligned' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-5362596a85d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtp53_filtered\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilter_green_fast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtp53_aligned\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mhe_filtered\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilter_green_fast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mgreen_end\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtp53_filtered\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilter_grays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtp53_filtered\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tp53_aligned' is not defined"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "tp53_filtered = filter_green_fast(tp53_aligned)\n",
    "he_filtered = filter_green_fast(he)\n",
    "green_end = time.time()\n",
    "tp53_filtered = filter_grays(tp53_filtered, tolerance = 3)\n",
    "he_filtered = filter_grays(he, tolerance = 15)\n",
    "gray_end = time.time()\n",
    "print('Time to Filter Green: {0}'.format(green_end - start))\n",
    "print('Time to Filter Gray: {0}'.format(gray_end - green_end))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
